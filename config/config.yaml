bot_name: "Name" # 里面填你机器人角色昵称or自设之类的?
API_token: "API_token" # 你的API token，没有自己上WeLM官网https://docs.qq.com/form/page/DUW1YVVJNbHpzV2No#/fill-detail申请
dhcommand_start: "welm" # 对话指令开头
wdcommand_start: "提问" # 问答指令开头
xxcommand_start: "续写" # 续写指令开头


# 模型参数调试专区(最好不碰,参数已由作者设定完成)
model: "xl" # 要使用的模型名称，当前支持的模型名称有medium、 large 和 xl
max_token: "128"  # 最小值?(注:此配置文件由兰罗摩编写并不是作者, 所以我也不知道)
max_token_xx: "256" # 最多生成的token个数，默认值 16
temperature: "0.85" # 默认值 0.85，表示使用的
top_p: "0.65" # 默认值 0.95，来源于nucleus sampling，采用的是累计概率的方式。
top_k: "0" # 默认值50，从概率分布中依据概率最大选择k个单词，建议不要过小导致模型能选择的词汇少。
n: "2" # 默认值 1 返回的序列的个数
stop: "\n" # 默认值 null，停止符号。当模型当前生成的字符为stop中的任何一个字符时，会停止生成。
twstop: "。" # 不知道是干什么的
priority: 60010 # 指令优先级, 默认值60010